name: Verify hashs of the documents
on:
  schedule:
    - cron: '0 8 * * 0' # run every sunday at (around) 8:00am UTC
  push: 
    branch: 
      - main
  workflow_dispatch:
    inputs:
      number_of_jobs:
        description: "Number of Jobs"
        required: true
        default: 20
      additional_args:
        description: "Additional arugments for download script"
        required: false
        default: "--limit 5"

jobs:
  generate-job-strategy-matrix:
    runs-on: ubuntu-latest
    outputs:
      job-strategy-matrix: ${{ steps.generate.outputs.job-strategy-matrix }}
    steps:
      - name: Generate indices
        id: generate
        run: |
          echo "::set-output name=job-strategy-matrix::[`seq -s , 0 $((NUMBER_OF_JOBS-1)) | sed 's/,$//'`]"
        env:
          NUMBER_OF_JOBS: ${{ github.event.inputs.number_of_jobs || 100 }}
  download-and-verify:
    needs: generate-job-strategy-matrix
    runs-on: ubuntu-latest
    timeout-minutes: 3600 # 60 hour timeout
    strategy:
      matrix:
        job: ${{ fromJson(needs.generate-job-strategy-matrix.outputs.job-strategy-matrix) }}
      max-parallel: ${{ fromJson(github.event.inputs.number_of_jobs || 100) }} # Run jobs in parallel
    steps:
      - uses: actions/checkout@v2
        with:
          path: download
          ref: ${{ github.ref }}
      - uses: actions/setup-python@v2
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          cd download
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt
      - name: Download and Verify
        run: |
          cd download
          python download_documents.py --storage ./data/ \
            --zho ./resource/zho/ids.*.jsonl.gz \
            --fas ./resource/fas/ids.*.jsonl.gz \
            --rus ./resource/rus/ids.*.jsonl.gz \
            --jobs 1 --rank ${{ matrix.job }} ${{ github.event.inputs.additional_args }} \
            --total_rank ${{ github.event.inputs.number_of_jobs }}
      - name: Count and Report
        run: |
          cd download/data
          total=`wc -l */*.jsonl | head -n 3 | awk '{s+=$1} END {print s}'`
          mismatch=`cat download_log.${{ matrix.job }}.txt | grep "\[hash-mismatch" | wc -l | awk '{print $1}'`
          printf "Hash mismatch: $mismatch/$total (%.4f%%)\n" `echo "$mismatch/$total*100" | bc`
      - name: Upload Logs
        uses: actions/upload-artifact@v3
        with: 
          name: logs
          path: ./download/data/*.txt
          retention-days: 90
      - name: Compress 
        run: | 
          gzip -9 download/data/*/*.jsonl
      - name: Upload documents
        uses: actions/upload-artifact@v3
        with: 
          name: docs
          path: ./download/data/*/*.jsonl.gz
          retention-days: 14

  aggregate-and-report:
    needs: [download-and-verify]
    if: ${{ always() }}
    runs-on: ubuntu-latest
    steps: 
      - uses: actions/checkout@v2
        with:
          path: download
          ref: ${{ github.ref }}
      - uses: actions/setup-python@v2
        with:
          python-version: '3.x'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install pandas tabulate
      - uses: actions/download-artifact@v3
        with:
          name: logs
          path: ./download/data
      - name: test
        run: |
          cd download
          python generate_action_report.py >> $GITHUB_STEP_SUMMARY
      
      